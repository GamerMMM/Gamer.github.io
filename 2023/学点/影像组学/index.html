<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon_medium.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon_small.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/fancybox/3.5.1/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gamermmm.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="一个对比AI影像和传统影像的论文，介绍各自的特征深度学习简单直接自动化，大力出奇迹；影像组学步步为营靠人工，识珠靠慧眼。两种方法本质上都依赖大数据，都可以划分为图像预处理、特征筛选和特征建模三个阶段。 传统影像组学方法上，影像组学提取传统的图像特征，包括形状、灰度、纹理等，采用传统统计（模式识别）模型来分类和预测，如支持向量机、随机森林、XGBoost等；Overview AI影像组学深度学习人工">
<meta property="og:type" content="article">
<meta property="og:title" content="影像组学">
<meta property="og:url" content="https://gamermmm.github.io/2023/%E5%AD%A6%E7%82%B9/%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6/">
<meta property="og:site_name" content="Gamer&#39;s Show">
<meta property="og:description" content="一个对比AI影像和传统影像的论文，介绍各自的特征深度学习简单直接自动化，大力出奇迹；影像组学步步为营靠人工，识珠靠慧眼。两种方法本质上都依赖大数据，都可以划分为图像预处理、特征筛选和特征建模三个阶段。 传统影像组学方法上，影像组学提取传统的图像特征，包括形状、灰度、纹理等，采用传统统计（模式识别）模型来分类和预测，如支持向量机、随机森林、XGBoost等；Overview AI影像组学深度学习人工">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic4.zhimg.com/v2-f6a1971f7bd966f887c80a6b6afdce53_r.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-0d05d6872495dc94b788d526756f9c2e_1440w.webp">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-0e0f70828404e5f5726e06d034bee348_1440w.webp">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-5d2b1d2feeaedce0ff8e73abb6e0d944_1440w.webp">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-9c5310d71e5e428662db1243f000b615_1440w.webp">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-558358a40a38f506aa5588d0e33a777c_1440w.webp">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-59d63f7881800e9147150a997646d6f4_1440w.webp">
<meta property="og:image" content="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-981-19-8338-2_26/MediaObjects/518611_1_En_26_Fig2_HTML.png?as=webp">
<meta property="article:published_time" content="2023-10-29T14:30:01.000Z">
<meta property="article:modified_time" content="2024-03-02T02:58:55.529Z">
<meta property="article:author" content="Gamer">
<meta property="article:tag" content="影像组学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic4.zhimg.com/v2-f6a1971f7bd966f887c80a6b6afdce53_r.jpg">

<link rel="canonical" href="https://gamermmm.github.io/2023/%E5%AD%A6%E7%82%B9/%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>影像组学 | Gamer's Show</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Gamer's Show</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">你知道人生最要紧的事是快乐不停</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-ghost fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-star-of-david fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/something/" rel="section"><i class="fa fa-cube fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://gamermmm.github.io/2023/%E5%AD%A6%E7%82%B9/%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Gamer">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gamer's Show">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          影像组学
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-10-29 22:30:01" itemprop="dateCreated datePublished" datetime="2023-10-29T22:30:01+08:00">2023-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-03-02 10:58:55" itemprop="dateModified" datetime="2024-03-02T10:58:55+08:00">2024-03-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/something/%E5%AD%A6%E7%82%B9/" itemprop="url" rel="index"><span itemprop="name">学点</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/ielx7/7433213/8657419/08657645.pdf?tag=1">一个对比AI影像和传统影像的论文，介绍各自的特征</a><br>深度学习简单直接自动化，大力出奇迹；影像组学步步为营靠人工，识珠靠慧眼。两种方法本质上都依赖大数据，都可以划分为图像预处理、特征筛选和特征建模三个阶段。</p>
<h1 id="传统影像组学"><a href="#传统影像组学" class="headerlink" title="传统影像组学"></a>传统影像组学</h1><p>方法上，影像组学提取传统的图像特征，包括形状、灰度、纹理等，采用传统统计（模式识别）模型来分类和预测，如支持向量机、随机森林、XGBoost等；<br><strong>Overview</strong><br><img src="https://pic4.zhimg.com/v2-f6a1971f7bd966f887c80a6b6afdce53_r.jpg" alt="Img"></p>
<h1 id="AI影像组学"><a href="#AI影像组学" class="headerlink" title="AI影像组学"></a>AI影像组学</h1><h2 id="深度学习人工智能模型"><a href="#深度学习人工智能模型" class="headerlink" title="深度学习人工智能模型"></a>深度学习人工智能模型</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/459735826">放射组学基于人工智能治疗预后</a><br>DL方法基于深度神经网络进行模式识别，模式识别通常包括一系列可训练的非线性操作，称为层，每个层将输入数据转换为便于模式识别的表示。随着越来越多的层对输入数据应用转换，这些数据越来越多地抽象为深层特征表示。由此产生的深层特征最终可以由网络的最后一层转化为所需的输出，例如治疗结果的可能性或肿瘤的分子亚型。深度学习是一个广泛的、技术性的、动态发展的领域。我们简要介绍了基于预测的AI影像学中最常见的主题，并对深层神经网络的类型、常用框架、解决数据局限性的方法进行了更详细的补充讨论。所有这些问题在别的研究中都有综述。</p>
<h2 id="VGG实现特征提取"><a href="#VGG实现特征提取" class="headerlink" title="VGG实现特征提取"></a>VGG实现特征提取</h2><h3 id="常用代码-注解"><a href="#常用代码-注解" class="headerlink" title="常用代码&amp;注解"></a>常用代码&amp;注解</h3><h4 id="查看模型结构"><a href="#查看模型结构" class="headerlink" title="查看模型结构"></a>查看模型结构</h4><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看模型整体结构</span></span><br><span class="line">structure = torch.nn.<span class="title class_">Sequential</span>(*list(vgg_model.children())[<span class="symbol">:</span>])</span><br><span class="line">print(structure)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看模型各部分名称</span></span><br><span class="line">print(<span class="string">&#x27;模型各部分名称&#x27;</span>, vgg_model._modules.keys())</span><br></pre></td></tr></table></figure>
<p>运行后可知：</p>
<ul>
<li><p>vgg19整体结构分为三大部分：</p>
<ul>
<li>‘features’：上面输出的VGG19模型结构中的第一个Sequential，包含（0）-（36）层；</li>
<li>‘avgpool’：VGG19模型结构的第二个部分AdaptiveAvgPool2d；</li>
<li>‘classifier’：VGG19模型结构的最后一个部分Sequential，包含（0）-（6）层。注意其中Linear特征维度是1000，其余均为4096.</li>
</ul>
</li>
</ul>
<h4 id="修改模型结构"><a href="#修改模型结构" class="headerlink" title="修改模型结构"></a>修改模型结构</h4><ol>
<li><p>可以获取各个部分，切割层数</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取vgg19模型的第一个Sequential, 也就是features部分.</span></span><br><span class="line">features = torch.nn.<span class="title class_">Sequential</span>(*list(vgg_model.children())[<span class="number">0</span>])</span><br><span class="line">print(<span class="string">&#x27;features of vgg19: &#x27;</span>, features)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取vgg19模型的最后一个Sequential, 也就是classifier部分.</span></span><br><span class="line">classifier = torch.nn.<span class="title class_">Sequential</span>(*list(vgg_model.children())[-<span class="number">1</span>])</span><br><span class="line">print(<span class="string">&#x27;classifier of vgg19: &#x27;</span>, classifier)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 在获取到最后一个classifier部分的基础上, 再切割模型, 去掉最后一层.</span></span><br><span class="line">new_classifier = torch.nn.<span class="title class_">Sequential</span>(*list(vgg_model.children())[-<span class="number">1</span>][<span class="symbol">:</span><span class="number">6</span>])</span><br><span class="line">print(<span class="string">&#x27;new_classifier: &#x27;</span>, new_classifier)</span><br></pre></td></tr></table></figure></li>
<li><p>用new_classifier替换vgg19原始模型中的分类器( classifier )部分，就得到了输出维度是4096的VGG19模型</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision.models as models</span><br><span class="line">from torchvision import transforms</span><br><span class="line">from <span class="variable constant_">PIL</span> import <span class="title class_">Image</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取vgg19原始模型, 输出图像维度是1000.</span></span><br><span class="line">vgg_model_1000 = models.vgg19(pretrained=<span class="title class_">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 下面三行代码功能是:得到修改后的vgg19模型.</span></span><br><span class="line"><span class="comment"># 具体实现是: 去掉vgg19原始模型的第三部分classifier的最后一个全连接层, </span></span><br><span class="line"><span class="comment"># 用新的分类器替换原始vgg19的分类器，使输出维度是4096.</span></span><br><span class="line">vgg_model_4096 = models.vgg19(pretrained=<span class="title class_">True</span>)</span><br><span class="line">new_classifier = torch.nn.<span class="title class_">Sequential</span>(*list(vgg_model_4096.children())[-<span class="number">1</span>][<span class="symbol">:</span><span class="number">6</span>])</span><br><span class="line">vgg_model_4096.classifier = new_classifier</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取和处理图像</span></span><br><span class="line">image_dir = <span class="string">&#x27;/mnt/image_test.jpg&#x27;</span></span><br><span class="line">im = <span class="title class_">Image</span>.open(image_dir)</span><br><span class="line">trans = transforms.<span class="title class_">Compose</span>([</span><br><span class="line">        transforms.<span class="title class_">Resize</span>((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.<span class="title class_">ToTensor</span>(),</span><br><span class="line">        transforms.<span class="title class_">Normalize</span>(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">])</span><br><span class="line">im = trans(im)</span><br><span class="line">im.unsqueeze_(dim=<span class="number">0</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用vgg19得到图像特征.</span></span><br><span class="line"><span class="comment"># 原始vgg19模型</span></span><br><span class="line">image_feature_1000 = vgg_model_1000(im).data[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">&#x27;dim of vgg_model_1000: &#x27;</span>, image_feature_1000.shape)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 修改后的vgg19模型</span></span><br><span class="line">image_feature_4096 = vgg_model_4096(im).data[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">&#x27;dim of vgg_model_4096: &#x27;</span>, image_feature_4096.shape)</span><br></pre></td></tr></table></figure>
</li>
<li><p>简化版本：只需要原始vgg19模型的第一个部分features部分的输出结果.但是只适用于联网加载的vgg19模型（即设置了pretrained&#x3D;True的模型），不适用于使用了本地vgg19模型的vgg_model</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取vgg19原始模型的features部分的前34个结构, 得到新的vgg_model模型.</span></span><br><span class="line">vgg_model = models.vgg19(pretrained=<span class="title class_">True</span>).features[<span class="symbol">:</span><span class="number">34</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 但是下面的代码只能得到classifier部分的前40个, </span></span><br><span class="line"><span class="comment"># 而不能得到包含features及avgpool及classifier的一共前40个结构.</span></span><br><span class="line"><span class="comment"># 所以这个方法不能实现输出4096维度图像特征的目标．</span></span><br><span class="line"><span class="comment"># vgg_model = models.vgg19(pretrained=True).classifier[:40]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>一些小tips</p>
<ol>
<li>修改特征类型 <figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">    把<span class="string">`VGG16_Weights.IMAGENET1K_FEATURES`</span></span><br><span class="line">改成<span class="string">`VGG16_Weights.IMAGENET1K_V1`</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="用于预测的卷积神经网络"><a href="#用于预测的卷积神经网络" class="headerlink" title="用于预测的卷积神经网络"></a>用于预测的卷积神经网络</h2><p>在放射学中，大多数基于DL的生物标记物应用都使用卷积神经网络从成像数据得出预测（图3a）。<strong>卷积神经网络是神经网络的一种特殊形式，用于学习图像的空间特征</strong>，并且由于它们在诊断任务中的表现，受到了广泛的关注。在几项引人注目的研究中，基于CNN的模型在诊断胸片和CT以及数字乳房X光摄影方面甚至超过了专业的人类专家。正如CNN已被证明能够学习指示恶性肿瘤的图像特征一样，越来越多的研究表明，它们可以根据与预后、风险和分子特征相关的肿瘤性质的细微差异对患者进行分型（图3a）。当使用患者结果数据进行训练时，CNN的卷积层可以学会识别反映预后的新成像表型。CNN可以应用于2D或3D输入，并且可以使用多个输入，以便从图像类型的组合中学习，例如<strong>多参数或动态MRI扫描</strong>。大量的CNN结构可以选择来用于基于AI的生物标记物研究（补充表2）。补充框2中进一步详细讨论了它们的原理和优势。<br><img src="https://pic3.zhimg.com/80/v2-0d05d6872495dc94b788d526756f9c2e_1440w.webp" alt="Img"></p>
<ul>
<li><p>用于预测的卷积神经网络（CNN）模型示例。输入图像或体积通过CNN层，CNN层执行操作并将其转换为目标输出向量。卷积层是将成像数据转换为深度特征表示的一组操作。每个过滤器通过图像，并与非线性激活函数配对，以强调特定任务感兴趣的视觉模式。随着更多的卷积层层叠，CNN可以在图像中学习到更复杂的视觉模式。在整个CNN分类器中，深度特征通过池化操作定期聚合。经过卷积层和池化层处理后，深度特征表示最终被展平为向量。接下来，完全连接的层将这些CNN衍生的图像特征转换为对应于目标输出的向量。这些模型可用于预测治疗反应、预测、肿瘤亚型和生物标志物的分类以及生理值的预测。</p>
</li>
<li><p>全卷积神经网络是一种CNN类型，只包含产生图像输出的卷积层，如肿瘤位置图。</p>
</li>
<li><p>完全连接的网络可以根据非图像数据进行训练，如影像组学特征和临床变量。</p>
</li>
<li><p>当对模型进行结果预测训练时，对大量数据的需求可能会存在局限性，在这种情况下，可行的患者数据可能比诊断研究更加有限。幸运的是，尽管训练数据很少，但有几种方法可以利用神经网络的优势。例如，<strong>迁移学习，其中针对一个模式识别任务训练的模型被重新调整用途以执行新任务，经常用于在训练数据大幅减少的情况下实现强大的CNN性能</strong>其他方法可用于处理有限或有缺陷的训练数据。</p>
</li>
</ul>
<h2 id="一些论文"><a href="#一些论文" class="headerlink" title="一些论文"></a>一些论文</h2><h3 id="一个特征提取网络的介绍"><a href="#一个特征提取网络的介绍" class="headerlink" title="一个特征提取网络的介绍"></a><a target="_blank" rel="noopener" href="https://blog.csdn.net/cc1609130201/article/details/130921342?ops_request_misc=&request_id=&biz_id=102&utm_term=MRIVGG-Net&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-130921342.142%5Ev96%5Epc_search_result_base3&spm=1018.2226.3001.4187">一个特征提取网络的介绍</a></h3><p><strong>Deep Feature——用深度网络来提取特征</strong></p>
<h3 id="Pure-DL直接使用Autoencoder来提取特征，然后直接进行分类。"><a href="#Pure-DL直接使用Autoencoder来提取特征，然后直接进行分类。" class="headerlink" title="Pure DL直接使用Autoencoder来提取特征，然后直接进行分类。"></a><a target="_blank" rel="noopener" href="http://devinderkumar.com/slides/crv_2015.pdf">Pure DL</a>直接使用Autoencoder来提取特征，然后直接进行分类。</h3><p>采用LIDC中已经标记（分割）好的肺结节病灶区域作为ROI，对ROI的最小包围矩形区域进行尺寸归一化，然后输入一个5层Autoencoder网络进行特征编码，对Autoencoder网络进行训练。之后，使用训练优化完成后的5层网络中的第4层网络输出，共200个特征向量，输入一个二值分类树，区分肺结节良恶性。<br><img src="https://pic1.zhimg.com/80/v2-0e0f70828404e5f5726e06d034bee348_1440w.webp" alt="Img"><br>但是这种方法准确度有待考量。</p>
<h3 id="！DL-Tr可以预测生存周期"><a href="#！DL-Tr可以预测生存周期" class="headerlink" title="！DL+Tr可以预测生存周期"></a>！<a target="_blank" rel="noopener" href="https://pubmed.ncbi.nlm.nih.gov/28871110/">DL+Tr</a>可以预测生存周期</h3><p>在传统的影像组学三大件（形状、灰度、纹理）之上，又添加了来自于深度学习网络的深度特征（Deep Feature）。所使用的深度学习网络包含5个卷积层和3个全连接层。倒数第二个（full7）和倒数第三个（full6）全连接层的输出，共8192个特征，与其他影像组学特征一起输入预测模型，来预测多形性成胶质细胞瘤患者的生存周期<br><img src="https://pic1.zhimg.com/80/v2-5d2b1d2feeaedce0ff8e73abb6e0d944_1440w.webp" alt="Img"></p>
<h3 id="！DRL"><a href="#！DRL" class="headerlink" title="！DRL"></a>！<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41598-017-05848-2">DRL</a></h3><p>直接采用CNN网络的输出作为特征，连接传统的分类器（预测器）进行分类和预测。作者在MR多模态影像上，测试和验证了DLR预测低级别胶质瘤突变分级的准确性。下方依次给出的是整体流程图，以及将DLR与传统影像组学方法的特异性、敏感性等对比、ROC对比。从对比可以看出，DLR方法在各项指标中几乎全面胜出。并且，对比中发现，采用多模态影像，并且对特征进行进一步筛选，得到的各项指标是最高的。<br><img src="https://pic2.zhimg.com/80/v2-9c5310d71e5e428662db1243f000b615_1440w.webp" alt="Img"><br><img src="https://pic1.zhimg.com/80/v2-558358a40a38f506aa5588d0e33a777c_1440w.webp" alt="Img"><br><img src="https://pic1.zhimg.com/80/v2-59d63f7881800e9147150a997646d6f4_1440w.webp" alt="Img"></p>
<h3 id="VGG-16-Architecture-for-MRI-Brain-Tumor-Image-Classification"><a href="#VGG-16-Architecture-for-MRI-Brain-Tumor-Image-Classification" class="headerlink" title="VGG-16 Architecture for MRI Brain Tumor Image Classification"></a><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-981-19-8338-2_26">VGG-16 Architecture for MRI Brain Tumor Image Classification</a></h3><ul>
<li>初始阶段是对样本图像进行预处理，然后使用池化层进行过滤，使用卷积层进行特征提取，最后使用架构模型的 FC 层进行分类。来自分子脑肿瘤数据库（REpository of Molecular BRAin Neoplasia DaTa，REMBRANDT）的核磁共振图像使用了预先训练好的模型架构，如视觉几何组（VGG）VGG-19、VGG-16、Inception-V3、Inception-V2、残差网络（ResNet）ResNet-18 和 ResNet-50。</li>
<li>The use of DL and TL methods to diagnose and classify brain tumors using MRI brain images has been proved to be a promising methodology.<strong>contains many CNN designs, including ResNet,Inception, and VGG networks.</strong></li>
<li>Figure 2 illustrates the CNN model’s architecture for brain tumor categorization.<img src="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-981-19-8338-2_26/MediaObjects/518611_1_En_26_Fig2_HTML.png?as=webp" alt="Img"><ul>
<li>从大脑图像中提取的深度特征被输入到设计的具有预训练特征的 CNN 模型中。**(GoogleNet)Inception-v2、Inception-V3、ResNet-18 [14]、ResNet-50 VGG-19 和 VGG-16 是本研究中使用的六个预训练 CNN 模型**。</li>
<li>最初，VGG-16 和 VGG-19 架构模型都将核磁共振成像脑图像作为输入。深度特征从网络的卷积层和最大池化层提取。随着深度的增加，分类误差也随之减少，直到达到 19 层时，分类误差才趋于饱和。研究人员还验证了深度在图形表示法中的重要性。</li>
<li>CNN performs better in larger datasets than the smaller ones. When it is not possible to produce a big training dataset, TL can be utilized.</li>
</ul>
</li>
<li>Conclusion: 具有 16 个网络层的 <strong>VGG-16</strong> 架构在将 MR 脑图像分类为肿瘤或正常图像方面提供了更高的准确度、精确度、F1 分数和召回率。</li>
</ul>
<h1 id="二者比较"><a href="#二者比较" class="headerlink" title="二者比较"></a>二者比较</h1><p>深度学习并没有完全取代影像组学。主要的原因还是数据集规模的限制。</p>
<p>深度学习能够大幅提高分类或预测模型的准确性，但这是有代价的。相比影像组学，深度学习方法需要更多的训练数据。但影像组学所研究的问题往往是某种肿瘤的分期或分型，或者是预后生存率，此类问题的训练数据（Grand Truth数据）收集成本是非常高昂的，一般需要病理或术后随访来进行验证。因此，训练数据集的规模通常数量级在几百，与深度学习常见的数千、上万级数据集相差很远。</p>
<p>可以采用深度学习中普遍采用的数据增强手段（Data Augmented）了。这在一定程度上弥补了数据缺口。而数据增强在传统的影像组学中是无法采用的。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>Gamer
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="https://gamermmm.github.io/2023/%E5%AD%A6%E7%82%B9/%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6/" title="影像组学">https://gamermmm.github.io/2023/学点/影像组学/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6/" rel="tag"># 影像组学</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/%E5%AD%A6%E7%82%B9/Visualize/" rel="prev" title="Visualize">
      <i class="fa fa-chevron-left"></i> Visualize
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/%E5%AD%A6%E7%82%B9/CNN/" rel="next" title="CNN">
      CNN <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6"><span class="nav-number">1.</span> <span class="nav-text">传统影像组学</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#AI%E5%BD%B1%E5%83%8F%E7%BB%84%E5%AD%A6"><span class="nav-number">2.</span> <span class="nav-text">AI影像组学</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">深度学习人工智能模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGG%E5%AE%9E%E7%8E%B0%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-number">2.2.</span> <span class="nav-text">VGG实现特征提取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81-%E6%B3%A8%E8%A7%A3"><span class="nav-number">2.2.1.</span> <span class="nav-text">常用代码&amp;注解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.2.1.1.</span> <span class="nav-text">查看模型结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="nav-number">2.2.1.2.</span> <span class="nav-text">修改模型结构</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E4%BA%8E%E9%A2%84%E6%B5%8B%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">2.3.</span> <span class="nav-text">用于预测的卷积神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E8%AE%BA%E6%96%87"><span class="nav-number">2.4.</span> <span class="nav-text">一些论文</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%B8%AA%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="nav-number">2.4.1.</span> <span class="nav-text">一个特征提取网络的介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pure-DL%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8Autoencoder%E6%9D%A5%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%EF%BC%8C%E7%84%B6%E5%90%8E%E7%9B%B4%E6%8E%A5%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%E3%80%82"><span class="nav-number">2.4.2.</span> <span class="nav-text">Pure DL直接使用Autoencoder来提取特征，然后直接进行分类。</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EF%BC%81DL-Tr%E5%8F%AF%E4%BB%A5%E9%A2%84%E6%B5%8B%E7%94%9F%E5%AD%98%E5%91%A8%E6%9C%9F"><span class="nav-number">2.4.3.</span> <span class="nav-text">！DL+Tr可以预测生存周期</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%EF%BC%81DRL"><span class="nav-number">2.4.4.</span> <span class="nav-text">！DRL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG-16-Architecture-for-MRI-Brain-Tumor-Image-Classification"><span class="nav-number">2.4.5.</span> <span class="nav-text">VGG-16 Architecture for MRI Brain Tumor Image Classification</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E8%80%85%E6%AF%94%E8%BE%83"><span class="nav-number">3.</span> <span class="nav-text">二者比较</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Gamer</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/something/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-shield-dog"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gamer.</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://cdn.bootcdn.net/ajax/libs/fancybox/3.5.1/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  













<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : '[object Object]',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  

  

</body>
</html>
